# --------------------------------------------------------------------------------------------------
# Paths
path:
    # model_directory: "models_cache/${run_name}"
    data_directory: "datasets"
    official_data_directory: None
    model_directory: None

    # mlflow directory setting
    # model_dir: "models/"
    # sample_dir: "samples/"
    # log_dir: "logs/"
    mlflow_dir: "./mlruns" # relative path to the project root



# --------------------------------------------------------------------------------------------------
# exp settings
exp:
    exp_name: "rsn-raw-bce"
    # run_name: "mlp-hrv_0001"

    # training parameters
    # site: "all" # "all" or list: [WFDB_CPSC2018, WFDB_CPSC2018_2, WFDB_StPetersburg, WFDB_PTB, WFDB_PTBXL, WFDB_Ga, WFDB_ChapmanShaoxing, WFDB_Ningbo]
    # sites: ["WFDB_CPSC2018","WFDB_CPSC2018_2","WFDB_StPetersburg","WFDB_PTB"]
    train_sites: ["WFDB_CPSC2018", "WFDB_CPSC2018_2", "WFDB_PTBXL", "WFDB_Ga", "WFDB_Ningbo"]
    eval_sites: ["WFDB_CPSC2018", "WFDB_CPSC2018_2", "WFDB_PTBXL", "WFDB_Ga", "WFDB_Ningbo"]
    # train_sites: ["WFDB_CPSC2018"]
    # eval_sites: ["WFDB_CPSC2018"]
    # sites: "all"
    ERASE_EXIST: True
    N_fold: 5
    N_fold_Order: 1 # order of the stratrification
    N_fold_Use_Unscored: False # whether to join the unscored samples for joint training
    random_state: 100
    model_type: "rsn_vanilla"

    # For final test (submission)
    top_N: 1 # choose top N models base on test_cm
    overlap_size: 256 # the size for segmenting the test patches 

# --------------------------------------------------------------------------------------------------
# features & labels
param_feature:
    # hrv_nk2:
    #     concat: True # whether concat all lead's features, currently only apply for hrv
    #     fea_types: ["fea_demo", "hrv_time", "hrv_nonlin", "ecg_rate_func10", "ecg_quality_func10", "ecg_phase_comp_vent_func10", "ecg_phase_comp_atrial_func10"]
        # fea_types: ['time', 'freq', 'nonlin', 'ECG_Rate', 'ECG_Quality', 'ECG_Phase_Completion_Atrial', 'ECG_Phase_Completion_Ventricular']
        # time: False # whether save the
    raw:
        sr: 500
        window: 10

    num_cpu: -1 # number of cpus for feature extraction, -1 menas #processer -1
    print_bar: True
    save_single_pkl: False


# preprocess
param_preprocess:
    impute: "median"
    scaler: "zscore"


# data laading / features
param_loader:
    num_leads: 2
    leads: ['I', 'II']
    replace_eq: True # combine equivalent labels
    num_workers: 8 # num_worker of pytorch dataloader
    resample: "None" # "LPRUS", "LPROS", "None"


# --------------------------------------------------------------------------------------------------
# trainer param
objective:
  type: "val_auprc"
  mode: "max"
param_trainer:
    max_epochs: 100
    check_val_every_n_epoch: 2
    progress_bar_refresh_rate: 5
    gpus: "0"
    auto_lr_find: True
    auto_scale_batch_size: "binsearch"
param_early_stop:
    monitor: ${objective.type}
    min_delta: 0.00
    patience: 5
    verbose: True
    mode: ${objective.mode}


# --------------------------------------------------------------------------------------------------
param_aug:
    # RemoveBaselineWander:
    #     cutoff: 0.05
    BandPass:
        cutoff: [3,45]
    Rescale: "minmax" # zscore / minmax
    RandomLeadMask: 0
    RandomShuflleLead: 0
    AddGaussianNoise:
        mean: 0
        std: 0.08
    RandomCrop: True


# --------------------------------------------------------------------------------------------------
#  model param
param_model:
    batch_size: 108
    in_channel: 2
    base_filters: 128
    first_kernel_size: 11
    kernel_size: 13
    stride: 3
    groups: 2
    n_block: 7
    n_demo: None
    output_size: 26
    lr: 0.004971290997807195
    scheduler_WarmUp:
        warmup: 1000
        max_iters: 10000
    sample_step: 1
    model_save_step: 1
    lambda_cal_l2: 0.01
    is_class_weight: false
    binary_thre_opt:
        method: 1
        n_trials: 2000
        mp: true
    is_se: true
    bce_loss_type: None
    is_cm_loss: false
    loss:
        name: AsymmetricLossOptimized
        gamma_neg: 4
        gamma_pos: 1
        clip: 0.15
        disable_torch_grad_focal_loss: true
    true_weight_decay: 0.0001
    use_ema: 0.9997


# --------------------------------------------------------------------------------------------------
logger:
    param_ckpt:
        # dirpath: ${model_directory}
        monitor: ${objective.type}
        filename: "{epoch:02d}-{${objective.type}:.3f}"
        save_top_k: 1
        mode: ${objective.mode}
    log_lightning: False